# 02/04/2019 论文学习总结  

  

## 经筛选可以参考实现的论文  

- [Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal Continuity and Sparseness Criteria](http://www.cs.tut.fi/sgn/arg/music/tuomasv/virtanen_taslp2007.pdf)  
- [Does Better Separation Imply Better Transcription](http://webhome.csc.uvic.ca/~gtzan/mmsp2013factors.pdf)  
- [Music Transcription with CNN by AnthemScore](https://www.lunaverus.com/cnn)    
- [Two-Stage Approach for A Speciæc Piano Transcription](https://www.google.com/url?q=https://www.mdpi.com/2076-3417/7/9/901/pdf&ust=1552442760000000&usg=AFQjCNGwCvyJKqq2jE7hCv-8WwKb5XTQIA&hl=zh-CN)  

  

  

## 结论  
有以下思路与猜想：  
- 要对多乐器作区分要使用Non-negative Matrix Factorization  
- AnthemScore通过将音频转化为频谱图，训练CNN对该频谱图进行分析识别音符  
> 由此不得不提的缺点是：不能区分多乐器，产生多乐器谱  

- 针对每一种可识别的乐器，要想办法找到一个合适的音色特征向量区间，来描述同一种乐器的音色，以容纳不同演奏乐器个体间的微小音色差异  
- NMF和AMT中都要对音频划分帧在处理。对多乐器的音频扒谱时可能有两种可行思路：先对整个音频进行NMF，再对导出的分离后的信号进行AMT；或先对一组相邻的帧顺序进行NMF与AMT后再处理下一组帧。  
> 讨论后我们（不太严谨暂时无从考证地）认为后者可能会带来更好的（也许差距没那么大的）效率  